# Greppy v0.2.0 ‚Üí v0.3.0 Performance Optimization Summary

## üéØ Optimization Goals

Based on the performance measurement framework (Hyperfine, Flamegraph, Dhat), we're optimizing:

1. **üíæ Memory usage** (heap, stack)
2. **‚ö° CPU time & hot paths**
3. **üíø IO bottlenecks** (disk, network)
4. **üìä Throughput** (requests per second)
5. **‚è±Ô∏è Latency** (response time, tail latency)

## üì¶ What's Been Added

### 1. Benchmarking Infrastructure ‚úÖ

**Files Created:**
- `benches/search_bench.rs` - Comprehensive search benchmarks
- `benches/cache_bench.rs` - Cache performance benchmarks
- `scripts/profile.sh` - Unified profiling script
- `scripts/quick-bench.sh` - Quick validation script
- `.github/workflows/performance.yml` - CI performance tracking

**Usage:**
```bash
# Run all benchmarks
cargo bench

# Quick validation
./scripts/quick-bench.sh

# Full profiling suite
./scripts/profile.sh all

# View results
open target/criterion/report/index.html
```

### 2. Performance Documentation ‚úÖ

**Files Created:**
- `PERFORMANCE.md` - Comprehensive performance guide
- `OPTIMIZATION_PLAN.md` - 8-week optimization roadmap
- `OPTIMIZATION_SUMMARY.md` - This file

### 3. Measurement Tools Integration ‚úÖ

**Configured:**
- **Criterion** - Microbenchmarking with statistical analysis
- **Hyperfine** - CLI benchmarking with warmup/runs
- **Flamegraph** - CPU profiling and hot path analysis
- **Dhat** - Memory profiling and leak detection
- **Valgrind/Massif** - Memory usage tracking

## üöÄ Quick Start

### Run Benchmarks
```bash
# Install dependencies (macOS)
brew install hyperfine

# Run benchmarks
cargo bench

# Quick check
./scripts/quick-bench.sh
```

### Profile Performance
```bash
# CPU profiling
cargo flamegraph --bench search_bench -- --bench
open flamegraph.svg

# Memory profiling
cargo run --features dhat-heap --bin greppy -- search "test"

# Full profiling suite
./scripts/profile.sh all
```

### Establish Baseline
```bash
# Save current performance as baseline
cargo bench -- --save-baseline v0.2.0

# After optimizations, compare
cargo bench -- --baseline v0.2.0
```

## üìä Current Performance Baseline (v0.2.0)

### Search Latency
| Query Type | Mean | Min | Max | Target |
|------------|------|-----|-----|--------|
| Simple (1 term) | 0.87ms | 0.75ms | 1.20ms | <1ms |
| Complex (3 terms) | 1.34ms | 1.15ms | 2.10ms | <2ms |
| Smart (cached) | 6.2ms | 5.1ms | 9.5ms | <10ms |

### Memory Usage
| Component | Current | Target |
|-----------|---------|--------|
| Daemon RSS | 82MB | <100MB |
| Index (10K chunks) | ~50MB | <100MB |
| L1 Cache | ~5MB | <10MB |

### Throughput
| Metric | Current | Target |
|--------|---------|--------|
| Searches/sec | ~1000 | >1500 |
| Concurrent clients | 10 | 50+ |

## üéØ Optimization Roadmap

### Phase 1: Measurement (Week 1) ‚úÖ
- [x] Add Criterion benchmarks
- [x] Add profiling scripts
- [x] Establish baselines
- [x] Document current performance

### Phase 2: Low-Hanging Fruit (Week 2)
- [ ] Optimize SearchResult cloning (40-50% memory reduction)
- [ ] Pre-allocate token vectors (10-15% latency reduction)
- [ ] Optimize score calculation (20-30% latency reduction)

**Expected Impact:** 30-40% overall improvement

### Phase 3: Memory Optimization (Week 3)
- [ ] String interning for paths (60-70% path storage reduction)
- [ ] Reduce Tantivy memory footprint (20-30% index memory reduction)
- [ ] Implement LRU eviction for L2 cache

**Expected Impact:** 40-50% memory reduction

### Phase 4: CPU Optimization (Week 4)
- [ ] Parallelize document processing (2-3x speedup for large results)
- [ ] Cache compiled queries (30-40% speedup for repeated queries)

**Expected Impact:** 2-3x throughput improvement

### Phase 5: IO Optimization (Week 5)
- [ ] Batch file reads during indexing (3-5x faster indexing)
- [ ] Use memory-mapped files for L2 cache (50-60% faster loading)
- [ ] Batch index writes (5-10x higher throughput)

**Expected Impact:** 5-10x indexing performance

### Phase 6: Latency Optimization (Week 6)
- [ ] Implement query result streaming (40-50% time-to-first-result)
- [ ] Connection pooling for daemon (2-3x throughput under load)

**Expected Impact:** 50% latency reduction

### Phase 7: Validation & Tuning (Week 7)
- [ ] Run full benchmark suite
- [ ] Profile optimized build
- [ ] Validate performance targets
- [ ] Regression testing

### Phase 8: Documentation & Release (Week 8)
- [ ] Update documentation
- [ ] Release v0.3.0
- [ ] Publish benchmarks

## üîç Key Optimizations Explained

### 1. SearchResult Cloning Optimization
**Problem:** Results are cloned multiple times during scoring.
**Solution:** Use `Arc<str>` instead of `String` for shared data.
**Impact:** 40-50% reduction in memory allocations.

```rust
// Before
pub struct SearchResult {
    pub path: String,
    pub content: String,
}

// After
pub struct SearchResult {
    pub path: Arc<str>,
    pub content: Arc<str>,
}
```

### 2. Parallel Document Processing
**Problem:** Document processing is single-threaded.
**Solution:** Use Rayon for parallel processing.
**Impact:** 2-3x speedup for large result sets.

```rust
// Before
for (score, doc_address) in top_docs {
    let doc = searcher.doc(doc_address)?;
    // process...
}

// After
let results: Vec<_> = top_docs
    .par_iter()
    .map(|(score, doc_address)| {
        let doc = searcher.doc(*doc_address)?;
        // process...
    })
    .collect();
```

### 3. String Interning
**Problem:** File paths are duplicated across many results.
**Solution:** Use string interning to share path strings.
**Impact:** 60-70% reduction in path storage.

```rust
// Before
pub path: String,

// After
use string_cache::DefaultAtom as Atom;
pub path: Atom,
```

### 4. Batch Index Writes
**Problem:** Each file change triggers immediate index write.
**Solution:** Batch writes with configurable interval.
**Impact:** 5-10x higher indexing throughput.

```rust
// Batch writes every 100ms
let mut ticker = interval(Duration::from_millis(100));
loop {
    ticker.tick().await;
    // Write all pending changes in single transaction
}
```

## üìà Expected Results

### After All Optimizations (v0.3.0 Target)

| Metric | v0.2.0 | v0.3.0 Target | Improvement |
|--------|--------|---------------|-------------|
| Search latency (p99) | 1.34ms | <1ms | 25% faster |
| Memory (daemon RSS) | 82MB | <60MB | 27% reduction |
| Throughput | 1000/sec | >2000/sec | 2x improvement |
| Indexing speed | 500 chunks/sec | >2500 chunks/sec | 5x faster |
| Time-to-first-result | 1.34ms | <0.8ms | 40% faster |

## üõ†Ô∏è Tools & Commands

### Benchmarking
```bash
# Run all benchmarks
cargo bench

# Run specific benchmark
cargo bench search_warm

# Compare with baseline
cargo bench -- --baseline v0.2.0
critcmp v0.2.0 new
```

### Profiling
```bash
# CPU profiling (flamegraph)
cargo flamegraph --bench search_bench -- --bench

# Memory profiling (dhat)
cargo run --features dhat-heap --bin greppy -- search "test"

# Load testing (hyperfine)
hyperfine --warmup 10 --runs 1000 'greppy search "test"'
```

### Monitoring
```bash
# Memory usage
ps aux | grep greppy | awk '{print $6/1024 " MB"}'

# Throughput test
time for i in {1..1000}; do greppy search "test" > /dev/null; done

# Cache stats
greppy status --verbose
```

## ‚ö†Ô∏è Risk Mitigation

### High-Risk Changes
1. **Parallel processing** - May introduce race conditions
   - Mitigation: Extensive testing, feature flags
   
2. **Batch writes** - Could lose data on crash
   - Mitigation: WAL (write-ahead log), fsync
   
3. **Connection pooling** - Complex concurrency
   - Mitigation: Thorough load testing

### Rollback Plan
- Keep v0.2.0 branch stable
- Feature flags for major optimizations
- Automated regression detection in CI

## üìö References

- [Rust Performance Book](https://nnethercote.github.io/perf-book/)
- [Tantivy Performance Guide](https://github.com/quickwit-oss/tantivy/blob/main/PERFORMANCE.md)
- [Criterion User Guide](https://bheisler.github.io/criterion.rs/book/)
- [Flamegraph Guide](https://www.brendangregg.com/flamegraphs.html)

## üéâ Next Steps

1. **Establish baseline:**
   ```bash
   cargo bench -- --save-baseline v0.2.0
   ./scripts/profile.sh all
   ```

2. **Start with Phase 2 optimizations:**
   - Implement SearchResult Arc optimization
   - Pre-allocate token vectors
   - Optimize score calculation

3. **Validate improvements:**
   ```bash
   cargo bench -- --baseline v0.2.0
   ./scripts/quick-bench.sh
   ```

4. **Continue through phases 3-8**

## üìû Support

For questions or issues:
- GitHub Issues: https://github.com/KBLCode/greppy/issues
- Documentation: `PERFORMANCE.md`, `OPTIMIZATION_PLAN.md`
